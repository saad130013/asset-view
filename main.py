import streamlit as st
import pandas as pd
import torch
from sklearn.metrics.pairwise import cosine_similarity
from transformers import AutoTokenizer, AutoModel

# ========== ุฅุนุฏุงุฏ ุงูุชุทุจูู ุงูุฃุณุงุณู ==========
st.set_page_config(
    page_title="๐ฆ ุงููุธุงู ุงูุฐูู ูุงูุชุฑุงุญ ุงูุฃุตูู",
    page_icon="๐ข",
    layout="wide"
)

# ========== ุชูุณูู CSS ูุฎุตุต ==========
st.markdown("""
<style>
    .stTextInput input {
        border: 2px solid #2e86c1 !important;
        border-radius: 10px;
        padding: 12px;
    }
    .stMarkdown h3 {
        color: #27ae60;
        border-bottom: 2px solid #3498db;
    }
    .result-card {
        background: #f8f9fa;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

# ========== ุชุญููู ุงูุจูุงูุงุช ==========
@st.cache_data
def load_data():
    try:
        df = pd.read_excel("assetv4.xlsx", header=1)
        df.columns = df.columns.str.strip()
        return df
    except Exception as e:
        st.error(f"๐จ ุฎุทุฃ ูู ุชุญููู ุงูููู: {str(e)}")
        st.stop()

df = load_data()
asset_descriptions = df["Asset Description For Maintenance Purpose"].dropna().astype(str).unique().tolist()

# ========== ุชุญููู ุงููููุฐุฌ ==========
@st.cache_resource
def load_bert_model():
    try:
        tokenizer = AutoTokenizer.from_pretrained("asafaya/bert-base-arabic")
        model = AutoModel.from_pretrained("asafaya/bert-base-arabic")
        return tokenizer, model
    except Exception as e:
        st.error(f"๐ค ุฎุทุฃ ูู ุชุญููู ุงููููุฐุฌ: {str(e)}")
        st.stop()

tokenizer, model = load_bert_model()

# ========== ุชูููุฏ ุงูุชุถูููุงุช ==========
@st.cache_data
def generate_embeddings():
    embeddings = []
    for desc in asset_descriptions:
        try:
            inputs = tokenizer(desc, return_tensors="pt", truncation=True, padding=True, max_length=32)
            with torch.no_grad():
                outputs = model(**inputs)
            embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()
            embeddings.append(embedding)
        except:
            embeddings.append([0.0]*768)
    return embeddings

embeddings = generate_embeddings()

# ========== ูุงุฌูุฉ ุงููุณุชุฎุฏู ==========
st.title("๐ค ูุธุงู ุงูุชุฑุงุญ ุงูุฃุตูู ุจุงุณุชุฎุฏุงู BERT ุงูุนุฑุจู")
user_input = st.text_input("โ๏ธ ุงูุชุจ ูุตู ุงูุฃุตู", placeholder="ูุซุงู: ุฌูุงุฒ ููุจููุชุฑ ูุญููู ูู ููุน ุฏูู")

# ========== ูุนุงูุฌุฉ ุงูุจุญุซ ==========
if user_input:
    with st.spinner('๐ ุฌุงุฑู ุงูุจุญุซ ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช...'):
        try:
            # ุชูููุฏ ุชุถููู ุงูุงุณุชุนูุงู
            inputs = tokenizer(user_input, return_tensors="pt", truncation=True, padding=True, max_length=32)
            with torch.no_grad():
                outputs = model(**inputs)
            query_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()
            
            # ุญุณุงุจ ุงูุชุดุงุจู
            similarities = cosine_similarity([query_embedding], embeddings)[0]
            top_indices = similarities.argsort()[-5:][::-1]
            
            # ุนุฑุถ ุงููุชุงุฆุฌ
            st.markdown("### ๐ก ุฃูุถู 5 ุงูุชุฑุงุญุงุช")
            for idx in top_indices:
                if similarities[idx] > 0.2:  # ููุชุฑุฉ ุงููุชุงุฆุฌ ุงูุถุนููุฉ
                    with st.container():
                        st.markdown(f"""
                        <div class="result-card">
                            <h4>{asset_descriptions[idx]}</h4>
                            <p style="color: #2e86c1;">ูุณุชูู ุงูุชุดุงุจู: {similarities[idx]:.2f}</p>
                            <p style="color: #27ae60;">ุงูุฑูุฒ: {df.iloc[idx]['Unique Asset Number in MoF system']}</p>
                        </div>
                        """, unsafe_allow_html=True)
            
            # ุฑุณู ุจูุงูู ููุชุดุงุจู
            st.markdown("### ๐ ุชูุฒูุน ุงูุชุดุงุจู")
            fig = pd.DataFrame({
                'ุงูุชุดุงุจู': similarities,
                'ุงููุตู': asset_descriptions
            }).plot(kind='hist', title='ุชูุฒูุน ุฏุฑุฌุงุช ุงูุชุดุงุจู').figure
            st.pyplot(fig)
            
        except Exception as e:
            st.error(f"โ ุญุฏุซ ุฎุทุฃ ุบูุฑ ูุชููุน: {str(e)}")

# ========== ูุณู ุงููุณุงุนุฏุฉ ==========
with st.expander("โน๏ธ ุชุนูููุงุช ุงูุงุณุชุฎุฏุงู"):
    st.markdown("""
    **โจ ููุฒุงุช ุงููุธุงู:**
    - ุจุญุซ ุฐูู ุจุงุณุชุฎุฏุงู ุฃุญุฏุซ ููุงุฐุฌ ุงูุฐูุงุก ุงูุงุตุทูุงุนู
    - ููุชุฑุฉ ุชููุงุฆูุฉ ูููุชุงุฆุฌ ุบูุฑ ุฐุงุช ุงูุตูุฉ
    - ุนุฑุถ ูุฑุฆู ูููุชุงุฆุฌ ูุน ุชูุงุตูู ูุงููุฉ
    
    **๐ฏ ูุตุงุฆุญ ุงูุจุญุซ:**
    1. ุงุณุชุฎุฏู ุฃูุตุงููุง ูุงุถุญุฉ ููุญุฏุฏุฉ
    2. ุชุฌูุจ ุงูุฃุฎุทุงุก ุงูุฅููุงุฆูุฉ
    3. ุงุณุชุฎุฏู ุงููููุงุช ุงูููุชุงุญูุฉ ุงููููุฉ
    """)
