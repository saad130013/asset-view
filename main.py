
import streamlit as st
import pandas as pd

st.set_page_config(page_title="Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£ØµÙˆÙ„ Ø§Ù„Ø°ÙƒÙŠ", layout="wide")
st.title("ğŸ“Š Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£ØµÙˆÙ„ - Ø§Ù„Ù‡ÙŠØ¦Ø© Ø§Ù„Ø¬ÙŠÙˆÙ„ÙˆØ¬ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
df = pd.read_excel("assetv4.xlsx", header=1)
df.columns = df.columns.str.strip()

# Ø£Ø³Ù…Ø§Ø¡ Ø¹Ø±Ø¨ÙŠØ© Ù„Ù„Ø¹Ø±Ø¶
arabic_labels = {
    "Custodian": "Ø§Ù„Ù…Ø³ØªÙ„Ù…", "Consolidated Code": "Ø§Ù„Ø±Ù…Ø² Ø§Ù„Ù…ÙˆØ­Ø¯", "Unique Asset Number in MoF system": "Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ù…ÙˆØ­Ø¯ ÙÙŠ ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ù…Ø§Ù„ÙŠØ©",
    "Linked/Associated Asset": "Ø§Ù„Ø£ØµÙ„ Ø§Ù„Ù…Ø±ØªØ¨Ø·", "Unique Asset Number in the entity": "Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ù…ÙˆØ­Ø¯ ÙÙŠ Ø§Ù„Ø¬Ù‡Ø©",
    "Asset Description": "ÙˆØµÙ Ø§Ù„Ø£ØµÙ„", "Tag number": "Ø±Ù‚Ù… Ø§Ù„ÙˆØ³Ù…", "Base Unit of Measure": "ÙˆØ­Ø¯Ø© Ø§Ù„Ù‚ÙŠØ§Ø³",
    "Quantity": "Ø§Ù„ÙƒÙ…ÙŠØ©", "Manufacturer": "Ø§Ù„Ø´Ø±ÙƒØ© Ø§Ù„Ù…ØµÙ†Ø¹Ø©", "Date Placed in Service": "ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ´ØºÙŠÙ„",
    "Cost": "Ø§Ù„ØªÙƒÙ„ÙØ©", "Depreciation amount": "Ù…Ø¨Ù„Øº Ø§Ù„Ø¥Ù‡Ù„Ø§Ùƒ", "Accumulated Depreciation": "Ø§Ù„Ø¥Ù‡Ù„Ø§Ùƒ Ø§Ù„Ù…ØªØ±Ø§ÙƒÙ…",
    "Residual Value": "Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©", "Net Book Value": "Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¯ÙØªØ±ÙŠØ©", "Useful Life": "Ø§Ù„Ø¹Ù…Ø± Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠ",
    "Remaining useful life": "Ø§Ù„Ø¹Ù…Ø± Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ", "Country": "Ø§Ù„Ø¯ÙˆÙ„Ø©", "Region": "Ø§Ù„Ù…Ù†Ø·Ù‚Ø©", "City": "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©",
    "Geographical Coordinates": "Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø§Ù„Ø¬ØºØ±Ø§ÙÙŠØ©", "National Address ID": "Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙˆØ·Ù†ÙŠ",
    "Building Number": "Ø±Ù‚Ù… Ø§Ù„Ù…Ø¨Ù†Ù‰", "Floors Number": "Ø¹Ø¯Ø¯ Ø§Ù„Ø·ÙˆØ§Ø¨Ù‚", "Room/office Number": "Ø±Ù‚Ù… Ø§Ù„ØºØ±ÙØ© / Ø§Ù„Ù…ÙƒØªØ¨"
}

# Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª
tab1, tab2 = st.tabs(["ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ØµÙ„", "ğŸ¤– Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø­Ø§Ø³Ø¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ"])

with tab1:
    try:
        search_input = st.text_input("ğŸ” Ø§Ø¨Ø­Ø« Ø¨Ø§Ø³Ù… Ø§Ù„Ø£ØµÙ„").strip().lower()
        filtered_options = df[
            df["Asset Description For Maintenance Purpose"].astype(str).str.lower().str.contains(search_input, na=False)
        ]["Asset Description For Maintenance Purpose"].dropna().unique().tolist()

        if filtered_options:
            selected_description = st.selectbox("ğŸ“„ Ø§Ø®ØªØ± Ø§Ù„Ø£ØµÙ„ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©:", filtered_options, key="select_asset_desc")

            asset_row = df[df["Asset Description For Maintenance Purpose"] == selected_description].iloc[0]

            # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
            general_fields = [
                "Custodian", "Consolidated Code", "Unique Asset Number in MoF system",
                "Linked/Associated Asset", "Unique Asset Number in the entity", "Asset Description", "Tag number",
                "Base Unit of Measure", "Quantity", "Manufacturer", "Date Placed in Service", "Cost",
                "Depreciation amount", "Accumulated Depreciation", "Residual Value", "Net Book Value",
                "Useful Life", "Remaining useful life", "Country", "Region", "City",
                "Geographical Coordinates", "National Address ID", "Building Number", "Floors Number", "Room/office Number"
            ]
            general_data = {field: asset_row.get(field) for field in general_fields if pd.notna(asset_row.get(field)) and asset_row.get(field) != "Not Available"}

            geo = general_data.pop("Geographical Coordinates", None)

            st.subheader("ğŸ“‹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©")
            table_data = [(f"ğŸ“ {arabic_labels.get(k, k)}", v) for k, v in general_data.items()]
            st.table(pd.DataFrame(table_data, columns=["ğŸ§¾ Ø§Ø³Ù… Ø§Ù„Ø­Ù‚Ù„", "Ø§Ù„Ù‚ÙŠÙ…Ø©"]))

            if geo and isinstance(geo, str) and "," in geo:
                try:
                    lat, lon = map(float, geo.split(","))
                    st.markdown("### ğŸ—ºï¸ Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø£ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø®Ø±ÙŠØ·Ø©")
                    st.map(pd.DataFrame({'lat': [lat], 'lon': [lon]}))
                except:
                    st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø¹Ø±Ø¶ Ø§Ù„Ø®Ø±ÙŠØ·Ø©: ØµÙŠØºØ© Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª ØºÙŠØ± ØµØ­ÙŠØ­Ø©.")

            if st.button("ğŸ“˜ Ø¹Ø±Ø¶ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø­Ø§Ø³Ø¨ÙŠØ©"):
                def get_safe(key):
                    val = asset_row.get(key, "")
                    return "ØºÙŠØ± Ù…ØªÙˆÙØ±" if pd.isna(val) or val == "" else val

                accounting_df = pd.DataFrame([
                    ["ğŸ¯ " + get_safe("Level 1 FA Module Code"), get_safe("Level 1 FA Module - English Description"), get_safe("Level 1 FA Module - Arabic Description")],
                    ["ğŸ·ï¸ " + get_safe("Level 2 FA Module Code"), get_safe("Level 2 FA Module - English Description"), get_safe("Level 2 FA Module - Arabic Description")],
                    ["ğŸ”’ " + get_safe("Level 3 FA Module Code"), get_safe("Level 3 FA Module - English Description"), get_safe("Level 3 FA Module - Arabic Description")],
                    ["ğŸ’¼ " + get_safe("accounting group Code"), get_safe("accounting group English Description"), get_safe("accounting group Arabic Description")],
                    ["ğŸ“¦ " + get_safe("Asset Code For Accounting Purpose"), "Asset Code For Accounting Purpose", "â€”"]
                ], columns=["Ø§Ù„ÙƒÙˆØ¯", "Ø§Ù„ÙˆØµÙ Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©", "Ø§Ù„ÙˆØµÙ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"])
                st.table(accounting_df)

        elif search_input:
            st.warning("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£ØµÙˆÙ„ Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù„Ø¨Ø­Ø«.")
    except Exception as e:
        st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø£Ùˆ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {str(e)}")

with tab2:
    user_desc = st.text_input("ğŸ§  Ø£Ø¯Ø®Ù„ ÙˆØµÙ Ø§Ù„Ø£ØµÙ„ Ù„ØªØµÙ†ÙŠÙÙ‡ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§:")

    if user_desc:
        found = False
    for word in user_desc.split():
        user_vec = vectorizer.transform([word])
        similarities = cosine_similarity(user_vec, tfidf_matrix)
        top_index = similarities.argmax()
        top_desc = descriptions_list[top_index]
        match_row = df[df['Asset Description For Maintenance Purpose'] == top_desc].iloc[0]
        table_data = [
            ['ğŸ¯ ' + str(match_row.get('Level 1 FA Module Code', 'â€”')), match_row.get('Level 1 FA Module - Arabic Description', 'â€”'), 'Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 1'],
            ['ğŸ·ï¸ ' + str(match_row.get('Level 2 FA Module Code', 'â€”')), match_row.get('Level 2 FA Module - Arabic Description', 'â€”'), 'Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 2'],
            ['ğŸ”’ ' + str(match_row.get('Level 3 FA Module Code', 'â€”')), match_row.get('Level 3 FA Module - Arabic Description', 'â€”'), 'Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 3'],
            ['ğŸ’¼ ' + str(match_row.get('accounting group Code', 'â€”')), match_row.get('accounting group Arabic Description', 'â€”'), 'Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ù…Ø­Ø§Ø³Ø¨ÙŠØ©'],
            ['ğŸ“¦ ' + str(match_row.get('Asset Code For Accounting Purpose', 'â€”')), 'Asset Code For Accounting Purpose', 'Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ']
        ]
        st.markdown('### ğŸ“˜ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØµÙ†ÙŠÙ')
        st.table(pd.DataFrame(table_data, columns=['Ø§Ù„ÙƒÙˆØ¯', 'Ø§Ù„ÙˆØµÙ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©', 'Ø§Ù„Ù…Ø³ØªÙˆÙ‰']))
        break
                table_data = [
                    ["ğŸ¯ " + (code_1[0] if len(code_1) > 0 else "â€”"), result["Level 1"], "Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 1"],
                    ["ğŸ·ï¸ " + (code_2[0] if len(code_2) > 0 else "â€”"), result["Level 2"], "Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 2"],
                    ["ğŸ”’ " + (code_3[0] if len(code_3) > 0 else "â€”"), result["Level 3"], "Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 3"],
                    ["ğŸ’¼ " + (code_g[0] if len(code_g) > 0 else "â€”"), result["Group"], "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ù…Ø­Ø§Ø³Ø¨ÙŠØ©"],
                    ["ğŸ“¦ " + (code_f[0] if len(code_f) > 0 else "â€”"), "Asset Code For Accounting Purpose", "Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"]
                ]
                st.markdown("### ğŸ“˜ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØµÙ†ÙŠÙ")
                st.table(pd.DataFrame(table_data, columns=["Ø§Ù„ÙƒÙˆØ¯", "Ø§Ù„ÙˆØµÙ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "Ø§Ù„Ù…Ø³ØªÙˆÙ‰"]))
                found = True
                break
        if not found:
            st.error("âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªØµÙ†ÙŠÙ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„ÙˆØµÙ.")

        found = False
    for word in user_desc.split():
        user_vec = vectorizer.transform([word])
        similarities = cosine_similarity(user_vec, tfidf_matrix)
        top_index = similarities.argmax()
        top_desc = descriptions_list[top_index]
        match_row = df[df['Asset Description For Maintenance Purpose'] == top_desc].iloc[0]
        table_data = [
            ['ğŸ¯ ' + str(match_row.get('Level 1 FA Module Code', 'â€”')), match_row.get('Level 1 FA Module - Arabic Description', 'â€”'), 'Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 1'],
            ['ğŸ·ï¸ ' + str(match_row.get('Level 2 FA Module Code', 'â€”')), match_row.get('Level 2 FA Module - Arabic Description', 'â€”'), 'Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 2'],
            ['ğŸ”’ ' + str(match_row.get('Level 3 FA Module Code', 'â€”')), match_row.get('Level 3 FA Module - Arabic Description', 'â€”'), 'Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 3'],
            ['ğŸ’¼ ' + str(match_row.get('accounting group Code', 'â€”')), match_row.get('accounting group Arabic Description', 'â€”'), 'Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ù…Ø­Ø§Ø³Ø¨ÙŠØ©'],
            ['ğŸ“¦ ' + str(match_row.get('Asset Code For Accounting Purpose', 'â€”')), 'Asset Code For Accounting Purpose', 'Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ']
        ]
        st.markdown('### ğŸ“˜ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØµÙ†ÙŠÙ')
        st.table(pd.DataFrame(table_data, columns=['Ø§Ù„ÙƒÙˆØ¯', 'Ø§Ù„ÙˆØµÙ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©', 'Ø§Ù„Ù…Ø³ØªÙˆÙ‰']))
        break